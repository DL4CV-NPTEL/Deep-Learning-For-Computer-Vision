{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week_8_Lecture_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa0744bb4aa34bdc98c6f213685c4c94": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f697199967f5458db6adada0e9c79139",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Video available at https://youtube.com/watch?v=c-k79rJagjQ\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.lib.display.YouTubeVideo at 0x7f894f463290>",
                  "text/html": "\n        <iframe\n            width=\"854\"\n            height=\"480\"\n            src=\"https://www.youtube.com/embed/c-k79rJagjQ?fs=1&rel=0\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ",
                  "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDBoYFhsaGRoeHRsfIS0lIiAiIycnJSYoLicyMC0wLS01PFBFNT5LOTUtRGFFS1VWW1xdM0FlbWRYbVBZW1cBERISGRYZLxsbL1dCNj1XV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1dXV1ddV1dXX1dXV1dXV1dXXV1dXVdXV//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAQUBAAAAAAAAAAAAAAAABQECAwQGB//EAEMQAAIBAgEGCAsHAwUBAQAAAAABAgMRBBITITGRkgUWQVFSU2HSFBUXIjNicXKxstEGMjRzgYKhQlTBIySTwvDhQ//EABkBAQADAQEAAAAAAAAAAAAAAAABAgMEBf/EACURAQACAQMEAwEBAQEAAAAAAAABAhEDMVESFCEyBBNBYfDRUv/aAAwDAQACEQMRAD8A8/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB2Hk4xvW4feqdweTjG9bh96p3AOPB2Hk4xvW4feqdweTjG9bh96fcA48HYeTjG9bh96p3B5OMb1uH3qncA48HU4r7BYukk5VKDu7aJT7prcUMT06O9Lugc+DoOKGJ6dHel3RxQxPTo70u6Bz4Og4oYnp0d6XdHFDE9OjvS7oHPg6DihienR3pd0cUMT06O9Lugc+DoOKGJ6dHel3RxQxPTo70u6Bz4Og4oYnp0d6XdHFDE9OjvS7oHPg6DihienR3pd0cUMT06O9Lugc+DoOKGJ6dHel3RxQxPTo70u6Bz4Og4oYnp0d6XdHFDE9OjvS7oHPg6DihienR3pd0cUMT06O9Lugc+DoOKGJ6dHel3RxQxPTo70u6Bz4Og4oYnp0d6XdHFDE9OjvS7oHPg6DihienR3pd0cUMT06O9Lugc+DoOKGJ6dHel3S+H2KxLV1Uo70+6BzgOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6BzQOl4kYrrKG9PujiRiusob0+6B62UKmtjqjjC8XZ3K3tFKzafxMRmcLeE8TKjh6lSKu4xuk9X6kR9m+GK2InOFW0rLKUkrW06maeJ4arwkrSUlpTjJJp6iyXDVSMlClCnSi8lvIirttJv4mH3RPl6FPjW6JriJmf3h2AIjgrF1KjWXK+zmZLmunqxqRMw4b0mk4lr4zDxqJKV9D5DU8WU/W2khV5DTx2JdKCko5Tc4wSvbTKSitP6misRmcQx+LKfrbR4sp+ttLsPjHKc6dSGbnCKk/OUo5LbSd9HM9ZndWKSk5RUXqd1Z/qCYmGt4sp+ttHiyn62028pc65v1KZyPSW1f+5HsCGr4sp+ttHiyn6202s5G9spXte11e3P7DHWxdOEJTlNKMNMnrtsCcSw+LKfrbR4sp+ttNpzWS5LSkr6CPwvDEatGnUUGnOpGDjfTFytZv9Gn+oTFZnZm8WU/W2jxZT9babWcjpWUrrXpWj28xVyXOgq1PFlP1to8WU/W2m0qsW7KUW7XtdXtz+wxYPEZ2lGolZSvo9ja/wE4li8WU/W2jxZT9baa+H4ajUoqrkNPOQg43V1lyiov2WkmSM60I5V5JZKvLTpS7UEzS0TiYa3iyn620eLKfrbTZp1oyjlRkmmr3vzlZVIx1yS5NLS0hXDV8WU/W2jxZT9baZcXiVSp1JuzcISlk3s3aLdv4M2WudcnLz6gnE4y1PFlP1to8WU/W2mfFVs3SnUtfIi5W57K5jljEnQWS/wDWdlp1eY5/4sCImVniyn620eLKfrbTNXxcIU51HJNQi5Ss03ZK5TD4jKjFzyYSlqipqV12PRcGJxli8WU/W2jxZT9baZaOJUsu9oqE3C7etq31GGxUZ04Tdo5epNq/s7Qnpli8WU/W2l8MFBKyvtLq2KjCdOGhucsnWrx8yUrtft/kzhExMMHgke0eCR7TOAhg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBg8Ej2jwSPaZwBsGpwl6N+3/BtmrjZU8m05ZPKZ6tZtSawtWcTEuL4Q+8va/gjFL0sf2fLE6KfB+DlNOVVytpyb6NNuZewyYjA4Kbi1JQehpp2ulq0P2HNHx74epHzNOMR5U4D1x9n+GTpF4OFCk1k1b6bWfPp0f+5iUNfj6dtOJi3Lzta8WtmFlXkI/hTDOrTjBK/+pTbV7eappy/gkZxuW5tnQzrPTOYQWI4KkoVadNeZKcKiaccp2fnQbkne1rq91psUo4BwcZOjKrC01kTdPKjKUk72Vo2enVq/Vk9m2M2yMNPutjCGWGqKpJZvzZV4VMrKjZRUIprnvdcxbT4JWbpxlTi268p1NWlZU3G/PocdBN5tjNvsGD7rICHBc1XnJqbvKcoyTpqFpRaSejK0arXtoTLKvA8szUhCnFZWFjC2jTUi3r+p0WbYzb7BhP3Wa0I3pWUMi8WlDRo2aCIhwXVisJkpeaqSrK+p07WkuflWw6DNsZt9hKldSa7OaXA9RQrRam6jp1IqTdPIk5u61JSu9GvUbdbBzrSqOdK0Z1KTyZOLeTD717P+CazbGbZGF/utuhZ4Sq8TCSpxjCFVNSioLzM246X95vktoVjd4MoSp0IQmrSV77zZu5t9gzb7CVLXm0Yc54prKlhslLKjm41o3WqFRTTXO15y/XsL6XBMs5Uc1OTbqNSbp5DU72voynyaHoVjoM2+wZtkYX+6zn58FzqKnFU81CdPIrK8U/N86DVvWvtK0sDVTVWtRjVnPLzkE4tKTyYxavofmxt+pP5t9gzbGD7rbf7/AH/EDHgmSo1sqMZVZYdU4SvfTkNWTerS7X5TaweElSU4zjnb1FNVHk5Ur8su2PwtYlM2+wZtjCJ1bTGJa2Lo5ylUp3tlwcb811Y0aVGpUlh8um6eYTbbcWpSzbhaNnq0t3diXzbGbfYSpFpiHNrgaaoZCpxUng5U5aVpqO2Tfn030mbFcGzedjGnF5yEY05rJWZaW1WfnK3Kyezb7Bm32EYX+6yEngZ5xTlTVWKqVHkXj/VGKjKz0aLNfuNV8EVLUsqM7KlGGTTlT81qTeuS0LVpjp0HS5tjNvsGE/dZBUOD5xq026avGvOpKteN5RlGeT26MqKt2E0X5tjNsYUvebbrAX5tjNslRYC/NvsGbfYBYC/NvsGbYFgL82+wZtgWAvzbGbYFgL82xm32AWAvzb7Bm32AWAvzb7Bm32AWAvzbGbYFgL82xm2BYC/NvsGbfYBYC/NvsGbfYBYC/NvsGbYGU15Ya7bzk9PJdWXs0GwUbAwLC2v/AKk9PavoWvCPkq1F+q+hhqcLU1PIgpVJc0Vcz0cWpSyZRcJa7Scb2/RkRbOycSPCt/8A6T2r6GanHJVrt9r1lxUlChUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAETw9iHGmoRdnL9L25L6OW3KSxFcO0JOEakVd03e3ZdP/BS/qtTdRLwSnbJveLbnou5pPX2f/e0rZYmCpyTaS9JfSnpScHz9pjxuFjWhJ04PJlBycrtXum0lftKYDg+MbZUcqDvJSvZpu9783/vYphbxjP6u4Cx85upQq6alF2ytPnK9r9r0fyS5zPADVXH4mslos1vSTV9LeqPMjpixqxEWVAAZgAAAAAAAAAAAEbwkr1aad7ZEnZNrljzExGZwiZwkihDZmPbvS+pWlBRq0mr/ft959F9pedOYR1JgqUKmawAAABQAVIrHRyq7TvZQjbS1rcuYxZmPbvS+peKTMZVm2EyVIjDRya1O19OVfS3yEsVmMThMTlUAEJAABQqUInExyq1S99GTbS1/SiYjM4RM4S5QhszHt3pfUzYCOTWsr2cHyt8sectNJiMoi2UoACiwAAAAAAAChU1uEW1Qm02nbWnZ7SPzfrVP+Sf1LVrlEzhMlCGzfrVP+Sf1JLAtujSbd24Ru3r1C1cETlsAAqkAAAAAAAAAAAoyprYzDupGKjLJtJO/suROyYUzOaTzcbpttwTSV3ravqI7G4bF4hZpKnQpPRLS5Sa5klrX6r9TZw/BjTTqSyrRSstT0NO/ZpLafBso5r7ryV53a73vqZTqtwvGInxLbwGChh6apw1Ln1t85smvgqU4U4wnZ5KSTTbv7bmwXjzCk7gAJQAAAAAAAAAAAR3CHpqfuT+MCRI7hD01P3J/GBam6LbMRSPpKXv/wDVkfDGTVapCo1GFJOUptWTjK2Rp7POT91c5IR9JS9//qzaZ8M43S4AOdqAAAAAIzF+nl7kfjMsL8X6eXuR+MiKwuOllVFVaiqTcG7fek25Jr9mS/1fMb0nxDK26Toemp/u+UlCLoempfu+UlDPU3XrsqACiwAAKEXW9NV9sflRKEVXX+tV5NXyovTdW2wX4P06/Ll80SKwGOlJN1Wo2kqdrWvOOibXZfR+hK4P06/Ll80TS3qpG6TABg1AAAAAAAAavCXoKns/yaZucJegqez/ACRHCOKdCCqWvBStPQ27NNK37snaa6eylm2b3B/oKXuR+CIzDybgsprLSSnk6lK2lEnwf6Cl7kfghqfhRsAAyXAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACO4Q9NT9yfxgSJGcJ1FGrTcmksiet25YFqbots1pYaLjUVrZy+U+V3VuUyQVp0vf8A+rMfhVPrIbyLqVaEqtJRlFvL1Jp/0s2tjDON00ChU52oAAABQCNxfp5e5H4zNOrgoyg4RbgnLKlbTlc6d76H/wDNRs46pGNd5Ukrwja7tyyMPhVPrI7yN6YwytuzUPTUv3fKSpEYWrGVenkyTtlanfkJczvuvXZUAFFgAAUIqt6ar7Y/KiVIjE1Yxr1MqSX3dbt/Si9N1bbNepgouEYRvGKd7Kzu731vTe+m+s3cH6dfly+aJreFU+sjvIz4CpGVfzZJ2g72d/6oml8YVrulQAYNAAAAAAAAGrwl6Cp7P8kfWoxnZSu0mna7Wlar8/sN/hN2w9RvVYjvCqXWQ3ka6allaNFQc7f1SctXOkSXB/oKXuR+CIzwql1kN5Enwf6Cl+XH4Ian4VbIAMlwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKSkkm3qQFQRXGPB9etkvoOMeD69bJfQr1V5V668sfCdGs8dgpQmo04ueVF3868dP8AGomCCxHDuFlWoyVZWi5X0S0XjZchs8Y8H162S+g6q8nXXlKgiuMWD69bJfQ3sJi6daGXSllRva+nk9pMWidiLRO0s4AJWAY61WMISnJ2jFNt8yRHcY8H162S+hEzEbom0RvKVIWtSr+NaM1OOZVCacNN350bvmvdx2My8Y8H162S+hqz4dwvhUKmeWSqU4t2lrcoNcnYyOqvKOuvKeKkVxjwfXrZL6DjHg+vWyX0HVXk668pUGLD4iFWCnTeVGWpmUssAGLE4iFKDnUeTGOtgZShF8Y8H162S+g4x4Pr1sl9CvVXlXrryxYelXXClebnF0XQglDTdedK3ZrU9qJkgYcO4VYmpPPLJdKEU7S1qU2+TtRtcYsH1y2S+g6q8nXXlKgiuMeD69bJfQkqNWM4xnF3jJJp86eomJidkxaJ2leACUgAAAoamI4Vw9KThUqxjJcjekiZxuiZiN22aHD0ajweIVJpTdOVm9CWjTq7LlPHuE6+G0wY7hrCyoVYxrwblCSSvrbiyOqOUddeW9wbGaw9JVXF1FCKk46m7a9JskZR4cwqhFOvC6S5ewv8e4Tr4bR1RyddeUiDUw3CdCtLJp1Yzla9k+Q2iYnKYmJ2VABKQAAAAAAAAAAAAAAAAAAAAAAAAAADFiPRz91/AymLEejn7r+BE7Il5WgESvB2IhCilKc4XraXBpO2StLTTujzaxmXl1jKKFyfpVKbnSjPNwkpzmmmslPOSvG/M1q9i5zDnKcou7ipwwyS1eenSWj3lL49hbo/q/R/UOd59j/wS9+XxODOy+y8a/gizUqSjlS+/GTd786ki/x/Zf4/u6YGjk4vp0P+OfeGTi+nQ/45947necNfg8R+VL5Weana4qGPVLFuvOg6GRPJUYyy7ZPJp0frc4o4/k7w4vk7woCZ4PxMIwoxc5JuU9CklBu6sp6NT5yuXTkoqThGdPDys9FpXpyTj7U2mv1Muj+sYpn9QwJnGVKU1iJJxU1CMbK3nrKhZrtWlP8ATtIYraMItGHon2a/A0fdfxZKEDwDHEeB0c3Kio5OhShJvW+VSRIZOL6dD/jn3j0aesPSp6w3SL+034Gt7F8yM+Ri+nQ/4594g8fDHLB4nwqdGUL+YoReXbLVru9vj7Rf1lF/WXIlLlSZw2JgqdKGU8rNS81ySpuWVLRLR/7QedWMvOrGUKCdztKTk7xUoUoR5PPVofyndez2GHH1Kc4V5xcVJ1YpxVtNnLzo9jVv1vzluj+p6PG6IPTOB/wlD8qHyo80PQeC3iPBqOTGjk5uNryle2Steg1+NvLf428pcoaeViujQ3p90o5Yro0N6fdOx2N0qRfAksc4f72NFS5M23f9y1bDeliYK93qvfQ+TX8QMpwP2t/HT92PwO+OB+1v46fux+Bh8j0c/wAj0QoNzguSVa7dkoz06Og7Wvykg8RTyctrOQdFpuWTltupG60amlqOSK5hxxXMZQYJyuqMabpuUZRkqUcta15s2pL9bX/UjuFEliKiVrXWrVqWoWrhNqYSn2N/Fv8ALl8UdycN9jfxb/Ll8Ud0dfx/R2fH9AAG7cAAAAAAAAAAAAAAAAAAAAAAAAAAAxYj0c/dfwMpSSurPUwPJ0VPSPEeE/t6e6h4jwn9vT3UcfbTy4u2ty82B2nCOEo08ZhaUMHGVOo5ZyShdLR5v86WSviPCf29PdQ7aeTtrcvNzu/sf+CXvy+Ju+I8J/b091G3hsNClHJpxUI67JWRpp6M0nLTS0ZpbMsoAOh0tHhr8HiPypfKzzU9Vq01OLjJJxkrNPU0zS8R4T+3p7qMNXSm8+GGrpTecw83KHpPiPCf29PdRE1sJRXCNLDrBxdKVGUnPI0ZV1bT2av3Iy7aeWPbW5cYVPSPEeE/t6e6h4jwn9vT3UO2nk7a3LH9mvwNH3X8WShjoUY04qEIqMVqS1IyHXWMRh2VjERARX2m/A1vYvmRKmOvRjUi4TipRetPUxaMxMItGYmHlZQ9J8R4T+3p7qHiTCf29PdRydtPLk7a3LzYHZ0MLRlwjVw7wcVSjSjKM8jQ5Xd9Pbq/ayW8R4T+3p7qHbTydtbl5uemcD/hKH5UPlRj8R4T+3p7qN2nTUIqMUlFKyS1JI10tKaT5baWlNJ8rwAbt1AVAFDgftb+On7sfgd8aWJ4Iw9WbnUpRlJ8rvyGerSbxiGWrSb1xDzUoejcX8J1EP5NLhngvDUMLWqww0ZThBuKSb08mg5+3ty5+2ty4YHfcH8EYWtQpVJYZRc4JuLTTTa0qxscX8J1EP5Hb25O2ty5j7G/i3+XL4o7k08LwVQoyy6VKMJWtdX1G4dGnSaVxLp0qTSuJVABo0AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoVIzhON6tNO9siei754BNYzOGbFfiMP7Z/IbhBvDwunbStTu9BfSgo1aTV15/O+iyMtJ0piMpkqUKksgAAChUoANKp+Np/kVPnpmvj4qVdp3soRtpfPIweDwvfJ02te7vYjLWunMxlOAiMJBRr07X05V9L5iXJUtXpnCoACoAAKAERioKVape7tk20vooLVr1ThtU/xlX8mn89Q3SD8Hhe+Tpta93exscHxSraL6YPlfPEjK9tOYjKVABLIAAAAAAABQ1uEvw1b8ufyscJNqhUs2nbWnZ7SNnRTTTc2noac52a2kZXrSbJih9yPur4F5CKkuee/P6kpgG3QpNttuEbt69QyWpNWwACVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAjeEfS0/cn8YEkRvCPpqfuT+MCJX0/aGEQ9JS9/8A6sjaeNkq9SNSSjRim4zaspNWylf1f5v2EjD0lL3/APqyHRac1lMFQCzkAAAAAEXjPTv3I/GRjMmM9O/cj8ZEPhMfLLqZ6VoRdqbcbZcbvzv0tb9L6mVl1UnFYS2H9PT/AHfKSpE4f01L93yksTDHV9lQASzAABQia/pqvtj8qJciMS/9aryavlREtNL2UMmC9Ovy5fNEiODsfKSefeS8pKKccnKjbRL92u3JqJfBenX5cvmiRDa85rKUABZygAAAAAAANXhL0FT2f5NE3uEvQVPZ/khOFMTOlTUqaUp5VlCz87Q72tqtr/TtIlvpeIlum/wf6Cl7kfgReHqKcItSU9C85am7c3ISnB/oKXuR+Ag1vxsgAlgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEbwj6Wn7k/jAkiM4UklVptuyyJ6f1gRK+n7Q16sFOEovVJNbUXU1/qUvf/wCrLM/DpLaVpVIyq0kmm8vk91kOi0xiU2ChUs5AAAAABF4z079yPxkauKoZyOTlOKvptbSuZ35DYx81Gu7u14Rtf2yMOfh0ltKy6qTHSy4b01L93yksRGEqKVenktO2Ve3sJcmGOp7KgAlmAAARFf01X2x+VEsQ+Kmo16mU0r5Ov3URLTS9mLE4fOJJyaSafJps7rXq9ptYL069yXzRNfPw6S2mbg+alX0O9oPV70SIbakx0ylgAWcoAAAAAAADV4S9BU9n+TRN3hN/7ep7CN8Jp9ZDeREt9HaSjRUHO39UnLVzpEpwf6Cl7kfgRfhNPrIbyJTg/wBBS9yPwQg1fxsgAlgAAAAAAAAAAAC3LXOtoy1zraBcC3LXOtpTOR51tAvBZnFzraM5HnW0C8FmcjzraM5HnW0C8FmcjzraM4udbQLwUKgAAAAAAoVAFAVAFCoAAAAChUAUKgAUBUAAAAAAFAVAFAVAAAAAAAAAAAAUGSioApZAqAAAAAAAAAAAAAADg5xMbijNMxtEyQwziiPjUhBycrK/1bJGbISVJ1a8aV7Rk9f8srEZWy2FiZVHahRlU7WmltL5VZQtnqTp3dr6HG/tJ+hiKVKMKMFKy0J20beU1MVi4ScoOMmtTbtYthETLSyVzIxVYq8dC1v4Mx4JtKcG75E3Fc9ta/gyVP6fe+qKLqZK5kbPBqXhVDQvSR+ZGubHBv4mh+ZD5kB6SACzMAAAFABUFCoAFCoAAAAAABQqAAAAAoBUAAAAAAAAFABUAAAAABQqAAAAAAAAAAAAAAAAAAKAVAKAcNNmKTKyZilISlbJmvwZh1KpCfLF/wAOCX0L8Q7QjLlyv4yTBgargspf+0IhO6c8Dp05ZxLKl7fqaM6FOc5OUMl30PlM7q5atF5L7TTyc29MrvmTb+Jr+IY50VCUmtcnd7Ev8GGq9CfrJfyvqZakru5gry8y3KpX/hfQxndZcZcK7VabWh5S+JieqL53JP8ARmxwZpxND8yPzIJdJ4VU6yW8x4VU6yW8zo81HorYhmo9FbEWZuTlj8Qm9M2k+d+ddXWzUy18KYjkjU1dJ21XOuzUeitiGaj0VsQHJrH4hxlaUlL+m7lZ3k1q9hZPhDEZEWnPKbldec7JXt/j/wCHX5qPRWxDNR6K2IDlcVjq0Y+ZOTlaVldu7UW0tpSOMr5Wmc7edovzSstLfNpOrzUeitiGaj0VsQHJQ4QxGUlKUkm0vvPT96/8JM2vCqnWS3mdHmo9FbEM1HorYgOc8KqdZLeY8KqdZLeZ0eaj0VsQzUeitiA5zwqp1kt5jwqp1kt5nR5qPRWxDNR6K2IDn6eJnb78t5l/hE+nLaydzceitgzceitgEF4RPpy2seET6ctrJ3Nx6K2DNx6K2AQXhE+nLazUlwhXy8lOTWVZtNuyv2fr/wC0HUZuPRWwZuPRWwtWYjeBzTxta07OV1NJfeV43jd9ut6ewsXCVfoT1asqXrdnYt46jNx6K2DNx6K2E9UcDlvGde/3alrPllpdtHJ+nxsV8ZV+jO2jllflvfR2LVz6LnUZuPRWwZuPRWwnrr/5HMrhCs4zdppqN4pyel82oSx1dxlk5akpJK7elZSTensOmzceitgzceithHVHA5Pw/F6tN3k2fnWX3cpPT2y09nYbGGx9ad8rLjbTpb03v8DpM3HorYM3HorYTa8TGMCC8In05bWPCJ9OW1k7m49FbBm49FbDMQXhE+nLax4RPpy2snc3HorYM3HorYBDwrzt9+W1lc/Lpy2smMhcy2DIXMtgEPn5dOW1jPy6ctrJjIXMtgyFzLYBD5+XTltYz8unLayYyFzLYMhcy2AQ+fl05bWM/Lpy2smMhcy2DIXMtgEPn5dOW1jPy6ctrJjIXMtgyFzLYBD5+XTltYz8unLayYyFzLYMhcy2AQ+fl05bWM/Lpy2smMhcy2DIXMtgEPn5dOW1mLFYqrGDcHJyVtGl8vMTuQuZbBkLmWwDn6uMqqMmpSuktCUpec9ehe1F2GxVWSlltpqWi2Uk1+pPZC5lsGQuZbAOBkyyXIXS1m7hMImlKa5LpE1ibT4RNorHlF1sLUqWjFLJ06W7K9jYwfBeROMZtSbWVo1WViRaU5ShrTirP+Ua+JrzhSUoRvUatlWuorlOiNOIZTqS0KtG+VHSpRdvauQ06qdOLfKtXtNylSqJudVyk+R6NHY+w28Vg4ZrOZSburLt7Sk0nK8XjCNpUG4x06cnT7UtJhxMHGErrken9DZwtCUfOTvlO77dJvyoXTurrlTL20YlWNSYQOW9XIm2n7bfQ3OCp/7qh+bH5kWcJYVU8lxTs217GY+CJf7uh+bD5kctoms4lvWcxl6mVKFSVQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHAYOnnKijyPX7CYrzyWua3w0fA4LDfamvSbcYUrvnUu8ZZfbHEt3yKO7LvGunaKx5ZalZtPh1sLJ5S5dC2szTVnJcj/APM4iH2qrxtaFLRe2iXK79Ivn9r8RLXCjuy7xpOrVT67Oylqa7CEUqs8RbNtU2uVWd9CfKQ/G/EdCjuy7xSP2sxCd8ilf2S7w+2E/XLsoRinJJaFaxkqRuvbGzOIj9rMQm3kUtPZLvF8vtfiWrZFHdl3h9lT67OgxMc7TlF62rr3iG4Hl/u8P+bD5kaK+0tdO+TT2S+pq0eF6kK0ayjDKjNTSs8m6d+fUZasxbEw10818S9xB5f5R8b1WH3anfHlHxvVYfdqd8zWeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgeoA8v8o+N6rD7tTvjyj43qsPu1O+B6gDy/yj43qsPu1O+PKPjeqw+7U74HqAPL/KPjeqw+7U748o+N6rD7tTvgceAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//2Q==\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f697199967f5458db6adada0e9c79139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/notebooks/Week_8/Week_8_Lecture_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 1: Recurrent Neural Networks: Introduction  <sup><mark style=\"background-color:gold\">Code</mark> </sup>\n",
        "\n"
      ],
      "metadata": {
        "id": "5p8aGbdxc1Nz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "aa0744bb4aa34bdc98c6f213685c4c94",
            "f697199967f5458db6adada0e9c79139"
          ]
        },
        "id": "W5BZQI44cxz_",
        "outputId": "4dda3d60-73c7-44a7-dfcf-2cea2b754e1c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa0744bb4aa34bdc98c6f213685c4c94"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title \n",
        "from ipywidgets import widgets\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"c-k79rJagjQ\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "display(out1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title \n",
        "from IPython import display as IPyDisplay\n",
        "IPyDisplay.HTML(\n",
        "    f\"\"\"\n",
        "  <div>\n",
        "    <a href= \"https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Slides/Week_8/DL4CV_Week08_Part01.pdf\" target=\"_blank\">\n",
        "    <img src=\"https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Data/Slides_Logo.png?raw=1\"\n",
        "  alt=\"button link to Airtable\" style=\"width:200px\"></a>\n",
        "    </div>\"\"\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "bJQjZzwxdQch",
        "outputId": "aa4313f2-ff49-44f6-c684-ad65da652ff0",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <div>\n",
              "    <a href= \"https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Slides/Week_8/DL4CV_Week08_Part01.pdf\" target=\"_blank\">\n",
              "    <img src=\"https://github.com/DL4CV-NPTEL/Deep-Learning-For-Computer-Vision/blob/main/Data/Slides_Logo.png?raw=1\"\n",
              "  alt=\"button link to Airtable\" style=\"width:200px\"></a>\n",
              "    </div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1AEVLnPtLJSc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['hey how are you','good i am fine','have a nice day']\n",
        "\n",
        "# Join all the sentences together and extract the unique characters from the combined sentences\n",
        "chars = set(''.join(text))\n",
        "\n",
        "# Creating a dictionary that maps integers to the characters\n",
        "int2char = dict(enumerate(chars))\n",
        "\n",
        "# Creating another dictionary that maps characters to integers\n",
        "char2int = {char: ind for ind, char in int2char.items()}"
      ],
      "metadata": {
        "id": "Osy0q1FLLJuM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(char2int)"
      ],
      "metadata": {
        "id": "WNk4ABtyLLz6",
        "outputId": "ae5cb845-f8b3-4d78-9f9d-78786fb620af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'m': 0, 'v': 1, ' ': 2, 'a': 3, 'h': 4, 'w': 5, 'f': 6, 'g': 7, 'u': 8, 'd': 9, 'i': 10, 'o': 11, 'e': 12, 'c': 13, 'r': 14, 'y': 15, 'n': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = len(max(text, key=len))\n",
        "print(\"The longest string has {} characters\".format(maxlen))"
      ],
      "metadata": {
        "id": "Kb96Hl8MLNFa",
        "outputId": "c9b64b2d-cefe-43fc-a89c-ae95d792de06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The longest string has 15 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "\n",
        "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
        "# the length of the longest sentence\n",
        "for i in range(len(text)):\n",
        "    while len(text[i])<maxlen:\n",
        "        text[i] += ' '"
      ],
      "metadata": {
        "id": "fEy3GBykLO57"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating lists that will hold our input and target sequences\n",
        "input_seq = []\n",
        "target_seq = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "    # Remove last character for input sequence\n",
        "    input_seq.append(text[i][:-1])\n",
        "    \n",
        "    # Remove firsts character for target sequence\n",
        "    target_seq.append(text[i][1:])\n",
        "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
      ],
      "metadata": {
        "id": "Fn1E16jELQi6",
        "outputId": "e22decbb-7ea7-4b7e-c6cc-3d2450b105b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: hey how are yo\n",
            "Target Sequence: ey how are you\n",
            "Input Sequence: good i am fine\n",
            "Target Sequence: ood i am fine \n",
            "Input Sequence: have a nice da\n",
            "Target Sequence: ave a nice day\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
        "    target_seq[i] = [char2int[character] for character in target_seq[i]]"
      ],
      "metadata": {
        "id": "SpoNVqhnLSEq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_size = len(char2int)\n",
        "seq_len = maxlen - 1\n",
        "batch_size = len(text)\n",
        "\n",
        "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
        "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "    \n",
        "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "    for i in range(batch_size):\n",
        "        for u in range(seq_len):\n",
        "            features[i, u, sequence[i][u]] = 1\n",
        "    return features"
      ],
      "metadata": {
        "id": "jay0WkkqLTkZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
        "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))"
      ],
      "metadata": {
        "id": "m3QvPx_gLVkJ",
        "outputId": "3412e44f-c14c-4ae8-9363-dadc7835e60b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (3, 14, 17) --> (Batch Size, Sequence Length, One-Hot Encoding Size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.from_numpy(input_seq)\n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "metadata": {
        "id": "z2JefTWCLXU6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "metadata": {
        "id": "8w3fgPycLYiB",
        "outputId": "2bbf9bff-9ceb-42bc-8cd1-2b9f2919cd6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "OyGbLs4vLZ-K"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 100\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "uXiMvGYvLdCi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Run\n",
        "input_seq = input_seq.to(device)\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "    #input_seq = input_seq.to(device)\n",
        "    output, hidden = model(input_seq)\n",
        "    output = output.to(device)\n",
        "    target_seq = target_seq.to(device)\n",
        "    loss = criterion(output, target_seq.view(-1).long())\n",
        "    loss.backward() # Does backpropagation and calculates gradients\n",
        "    optimizer.step() # Updates the weights accordingly\n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "metadata": {
        "id": "YS_XQT4-Levp",
        "outputId": "272e052b-676b-48c5-e241-c58c50331fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10/100............. Loss: 2.3994\n",
            "Epoch: 20/100............. Loss: 2.1219\n",
            "Epoch: 30/100............. Loss: 1.7932\n",
            "Epoch: 40/100............. Loss: 1.4265\n",
            "Epoch: 50/100............. Loss: 1.0763\n",
            "Epoch: 60/100............. Loss: 0.7782\n",
            "Epoch: 70/100............. Loss: 0.5391\n",
            "Epoch: 80/100............. Loss: 0.3706\n",
            "Epoch: 90/100............. Loss: 0.2625\n",
            "Epoch: 100/100............. Loss: 0.1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, character):\n",
        "    # One-hot encoding our input to fit into the model\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
        "    character = torch.from_numpy(character)\n",
        "    character = character.to(device)\n",
        "    \n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    # Taking the class with the highest probability score from the output\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "metadata": {
        "id": "XYu3DitBLkvd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, out_len, start='hey'):\n",
        "    model.eval() # eval mode\n",
        "    start = start.lower()\n",
        "    # First off, run through the starting characters\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "    # Now pass in the previous characters and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(model, chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "metadata": {
        "id": "mtWxIt0MLmY6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample(model, 15, 'good')"
      ],
      "metadata": {
        "id": "TyJ9AK4NLn5s",
        "outputId": "664eacf9-4fb2-4564-f299-07ab30674310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good i am fine '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Acknowledgements**"
      ],
      "metadata": {
        "id": "o1p_f5hcMGHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://blog.floydhub.com/a-beginners-guide-on-recurrent-neural-networks-with-pytorch/"
      ],
      "metadata": {
        "id": "CnBjITa5MBPr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7S2sujJWMBtK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}